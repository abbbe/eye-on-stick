{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install -r https://raw.githubusercontent.com/abbbe/eye-on-stick/main/requirements.txt\n",
    "    !git clone https://github.com/abbbe/eye-on-stick\n",
    "    %cd eye-on-stick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os, urllib, time\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"sqlite:///mlruns/db.sqlite\"\n",
    "import mlflow, git\n",
    "mlflow_client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "from stable_baselines.common.cmd_util import make_vec_env\n",
    "from stable_baselines.common.vec_env import VecNormalize\n",
    "from stable_baselines import PPO2, SAC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "from lib import eos\n",
    "from lib.eos import EyeOnStickEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-might",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "with git.Repo() as repo:\n",
    "    git_info = f'{repo.active_branch.name}/{repo.git.rev_parse(repo.head.object.hexsha, short=4)}'\n",
    "    if repo.is_dirty():\n",
    "        git_info = f'*{git_info}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.run import run_env_nsteps\n",
    "\n",
    "def log_metrics(metrics, step):\n",
    "    # log the content of metrics dict as mlflow metrics\n",
    "    for key, value in metrics.items():\n",
    "        mlflow.log_metric(key=key, value=value, step=step)\n",
    "\n",
    "def save_and_register_model(model, saved_models_dir, era, model_name, mlflow_run):    \n",
    "    # save the trained models, each era separately\n",
    "    model_fname = f'{saved_models_dir}/{era}'\n",
    "    model.save(model_fname)\n",
    "\n",
    "    # register the trained model\n",
    "    return mlflow_client.create_model_version(name=model_name, source=model_fname, run_id=mlflow_run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_and_run(n_joints, params, gym_policy_class=SAC, gym_model_name='MlpPolicy', name=None, display=None):\n",
    "    \"\"\"\n",
    "    1. Instanciates environment with n_joints and agent with given policy class and model name.\n",
    "    2. Step through the environment for N_STEPS steps, collecting metrics and rendering it (if render is True).\n",
    "    3. Log metrics into mlflow child per-era run and the parent run.\n",
    "    4. Train the policy model with the policy.\n",
    "    5. Save the model as mlflow artefact.\n",
    "    6. Repeat 2-5 N_ERAS times.\n",
    "    7. Returns file name to load the model from.\n",
    "    \"\"\"\n",
    "    env = make_vec_env(lambda: EyeOnStickEnv(n_joints, params), n_envs=N_ENVS)\n",
    "    #env = VecNormalize(env)\n",
    "        \n",
    "    run_name = f'eos.{n_joints}J'\n",
    "    model_name = run_name\n",
    "    if name is not None:\n",
    "        run_name += f' {name}'\n",
    "\n",
    "    # create new mlflow run which will become a parent of per-era runs\n",
    "    with mlflow.start_run(run_name=run_name) as parent_run:\n",
    "        # log gym  params\n",
    "        mlflow.log_param(\"gym_policy_class\", gym_policy_class.__name__)\n",
    "        mlflow.log_param(\"gym_model_name\", gym_model_name)        \n",
    "        for key, value in params.items():\n",
    "            mlflow.log_param(key, value)\n",
    "\n",
    "        # arrange tensorboard logs\n",
    "        mlflow_artifacts_dir = urllib.request.url2pathname(urllib.parse.urlparse(mlflow.get_artifact_uri()).path)\n",
    "        tensorboard_logdir = os.path.join(mlflow_artifacts_dir, \"tensorboard_log\")\n",
    "        os.makedirs(tensorboard_logdir, exist_ok=False)\n",
    "\n",
    "        # create gym model and directory to save it\n",
    "        model = gym_policy_class(gym_model_name, env, tensorboard_log=tensorboard_logdir)\n",
    "        saved_models_dir = os.path.join(mlflow_artifacts_dir, \"saved_models\")\n",
    "        os.makedirs(saved_models_dir, exist_ok=False)\n",
    "\n",
    "        ## run eras loop\n",
    "        metrics = None\n",
    "        for era in range(N_ERAS):\n",
    "            child_run_name = f'era={era}'\n",
    "            \n",
    "            with mlflow.start_run(run_name=child_run_name, nested=True) as child_run:            \n",
    "                env.reset()\n",
    "                model.learn(N_LEARN_EPOCHS)\n",
    "                registered_model = save_and_register_model(model, saved_models_dir, era, model_name, child_run)\n",
    "                mlflow.log_metric(\"model_version\", registered_model.version)\n",
    "\n",
    "                metrics = run_env_nsteps(env, model, N_STEPS, display=display)\n",
    "                log_metrics(metrics, step=era)\n",
    "                    \n",
    "        # log to the parent run\n",
    "        if metrics:\n",
    "            log_metrics(metrics, step=None)\n",
    "            \n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we run N_ERAS eras (=mlflow runs), each era consists of N_STEPS steps\n",
    "# at the end of each era we report metrics to mlflow and learn for N_LEARN_EPOCHS epochs\n",
    "N_ERAS = 25 # eras \n",
    "N_STEPS = 1000 # steps each\n",
    "N_LEARN_EPOCHS = 10000\n",
    "N_ENVS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arams = {\n",
    "#       'REWARD_AIM_WEIGHT': 1,\n",
    "#       'REWARD_LEVEL_WEIGHT': 0,\n",
    "#       'REWARD_ACTION_WEIGHT': 0,\n",
    "#       'GEAR_FUNC_NOISE': 0\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_and_run(n_joints=3, params={}, name='1651', display=display)\n",
    "\n",
    "#for round in range(N_RUN_ROUNDS):\n",
    "#    run(n_joints=4, policy_class=SAC, model_name='MlpPolicy', name=f'{git_info} {round+1}/{N_RUN_ROUNDS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-release",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
