{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "charitable-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython import display\n",
    "from io import BytesIO\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "optical-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure logging\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename='eye-on-stick.log', mode='w')\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "logging.getLogger('gym').setLevel(logging.DEBUG)\n",
    "\n",
    "# suppress trash from PIL and TF\n",
    "# https://github.com/camptocamp/pytest-odoo/issues/15\n",
    "logging.getLogger('PIL').setLevel(logging.ERROR)\n",
    "\n",
    "# https://github.com/hill-a/stable-baselines/issues/298\n",
    "import os\n",
    "# https://stackoverflow.com/questions/40426502/is-there-a-way-to-suppress-the-messages-tensorflow-prints/40426709\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
    "import warnings\n",
    "# https://stackoverflow.com/questions/15777951/how-to-suppress-pandas-future-warning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('INFO')\n",
    "tf.autograph.set_verbosity(0)\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "native-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showarray(img_array):\n",
    "    buf = BytesIO()\n",
    "    Image.fromarray(np.uint8(img_array)).save(buf, 'png')\n",
    "    display.display(display.Image(data=buf.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sixth-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LOW = 2\n",
    "X_HIGH = 3\n",
    "Y_LOW = -2\n",
    "Y_HIGH = 2\n",
    "\n",
    "SCREEN_SIZE = 500\n",
    "SCREEN_SCALE = SCREEN_SIZE / 7\n",
    "BG_COLOR = (0, 0, 0)\n",
    "BORDER_COLOR = (0, 128, 0)\n",
    "\n",
    "TEXT_COLOR = (128, 128, 128)\n",
    "LINE_HEIGHT = 15\n",
    "\n",
    "CIRCLE_SIZE = 0.05\n",
    "TARGET_CIRCLE_COLOR = (255, 0, 0)        \n",
    "EYE_CIRCLE_COLOR = (0, 0, 255)\n",
    "BASE_CIRCLE_COLOR = (0, 255, 0)\n",
    "\n",
    "STICK_LEN = 1.0\n",
    "STICK_WIDTH = 0.01\n",
    "STICK_COLOR = (128, 128, 128)\n",
    "\n",
    "PHI_AMP = np.pi/2\n",
    "DPHI_AMP = 10\n",
    "DPHI = np.pi/360\n",
    "ALPHA_GOAL = 2*DPHI\n",
    "\n",
    "N_ENVS = 32\n",
    "MAX_STEPS = 100\n",
    "\n",
    "MODEL_FNAME = None # \"eye-on-stick\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "printable-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyeOnStickEnv(gym.Env):    \n",
    "    metadata = {'render.modes': ['rgb_array']}\n",
    "    \n",
    "    ACC_PLUS = 2\n",
    "    ACC_ZERO = 1\n",
    "    ACC_MINUS = 0\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(EyeOnStickEnv, self).__init__()\n",
    "        self.base_x = 0\n",
    "        self.base_y = 0\n",
    "        self.stick_len = 1.0\n",
    "\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "        self.observation_space = spaces.Box(low=-1, high=1, shape=(4,), dtype=np.float32)\n",
    "        \n",
    "        self.nresets = 0\n",
    "        self.nsteps = 0\n",
    "    \n",
    "    def reset(self):\n",
    "        self.nresets += 1\n",
    "        self.nsteps = 0\n",
    "        self.actions_log = \"\"\n",
    "        self.info = dict(reward=0, reward_run=0, reward_ctrl=0)\n",
    "\n",
    "        # set random target location\n",
    "        self.target_x = np.random.uniform(low=X_LOW, high=X_HIGH)\n",
    "        self.target_y = np.random.uniform(low=Y_LOW, high=Y_HIGH)\n",
    "        self.phi_k = np.random.uniform(low=0.75, high=1.25) #* np.random.choice([-1, 1])\n",
    "        \n",
    "        # the stick is randomly oriented, but stationary\n",
    "        self.phi = 0 # np.random.uniform(low=-np.pi/2, high=np.pi/2)\n",
    "        self.phi_min = self.phi - PHI_AMP\n",
    "        self.phi_max = self.phi + PHI_AMP\n",
    "        self.dphi = 0\n",
    "        \n",
    "        self._recalc()\n",
    "        \n",
    "        return self.get_obs()\n",
    "    \n",
    "    def _recalc(self):    \n",
    "        # eye observes target as projection on retina\n",
    "        self.eye_x = self.stick_len * np.cos(self.phi)\n",
    "        self.eye_y = self.stick_len * np.sin(self.phi)\n",
    "        self.eye_phi = self.phi\n",
    "        \n",
    "        dx = self.target_x - self.eye_x\n",
    "        dy = self.target_y - self.eye_y\n",
    "        self.alpha = np.arctan2(dy, dx) - self.eye_phi\n",
    "              \n",
    "    def get_obs(self):\n",
    "        return np.array([np.sin(self.alpha), np.cos(self.alpha), self.alpha / PHI_AMP, self.dphi / DPHI_AMP]).astype(np.float32)\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.nsteps += 1\n",
    "        \n",
    "        alpha_before = self.alpha\n",
    "\n",
    "        if action == self.ACC_PLUS:\n",
    "            self.dphi += 1\n",
    "            action_char = '+'\n",
    "        elif action == self.ACC_MINUS:\n",
    "            self.dphi -= 1\n",
    "            action_char = '-'\n",
    "        elif action == self.ACC_ZERO:\n",
    "            action_char = 'o'\n",
    "        else:\n",
    "            raise ValueError(\"Received invalid action={} which is not part of the action space\".format(action))\n",
    "\n",
    "        self.actions_log += action_char\n",
    "        if len(self.actions_log) % 75 == 0:\n",
    "            self.actions_log += '\\n'\n",
    "\n",
    "        if self.dphi > DPHI_AMP:\n",
    "            self.dphi = DPHI_AMP\n",
    "        elif self.phi < -DPHI_AMP:\n",
    "            self.dphi = -DPHI_AMP\n",
    "            \n",
    "        self.phi += self.dphi * DPHI * self.phi_k\n",
    "        if self.phi > self.phi_max:\n",
    "            self.phi = self.phi_max\n",
    "            self.dphi = 0\n",
    "        elif self.phi < self.phi_min:\n",
    "            self.phi = self.phi_min\n",
    "            self.dphi = 0\n",
    "            \n",
    "        self._recalc()\n",
    "        \n",
    "        done = bool(np.abs(self.alpha) <= ALPHA_GOAL)\n",
    "        if done:\n",
    "            reward = 10\n",
    "            reward_info = f\"reward {reward:.3f}\"\n",
    "        else:\n",
    "            reward_ctrl = 0 #- 0.1 * np.square(self.dphi)\n",
    "            reward_run = (np.abs(alpha_before) - np.abs(self.alpha)) * 10\n",
    "            reward = reward_ctrl + reward_run\n",
    "            reward_info = f\"{reward:.3f} (run {reward_run:.3f} + ctrl {reward_ctrl:.3f})\"\n",
    "            \n",
    "        self.info = dict(reward=reward_info)\n",
    "        return self.get_obs(), reward, done, self.info\n",
    "\n",
    "\n",
    "    def render(self, mode='rgb_array'):\n",
    "        if mode != 'rgb_array':\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        image = Image.new('RGB', (SCREEN_SIZE, SCREEN_SIZE), BG_COLOR)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        draw.polygon([\n",
    "            (0, 0),\n",
    "            (0, SCREEN_SIZE-1),\n",
    "            (SCREEN_SIZE-1, SCREEN_SIZE-1),\n",
    "            (SCREEN_SIZE-1, 0),\n",
    "            (0, 0)\n",
    "        ], outline=BORDER_COLOR)\n",
    "            \n",
    "        def draw_circle(x, y, r, fill):\n",
    "            px = int(SCREEN_SIZE / 2 + x * SCREEN_SCALE)\n",
    "            py = int(SCREEN_SIZE / 2 + y * SCREEN_SCALE)\n",
    "            pr = int(r * SCREEN_SCALE)\n",
    "            draw.ellipse((px - pr, py - pr, px + pr, py + pr), fill=fill)        \n",
    "\n",
    "        def draw_line(x1, y1, x2, y2, fill, w):\n",
    "            px1 = int(SCREEN_SIZE / 2 + x1 * SCREEN_SCALE)\n",
    "            py1 = int(SCREEN_SIZE / 2 + y1 * SCREEN_SCALE)\n",
    "            px2 = int(SCREEN_SIZE / 2 + x2 * SCREEN_SCALE)\n",
    "            py2 = int(SCREEN_SIZE / 2 + y2 * SCREEN_SCALE)\n",
    "            pw = int(w * SCREEN_SCALE)\n",
    "            draw.line((px1, py1, px2, py2), fill=fill, width=pw)\n",
    "\n",
    "        def draw_text(pos, txt):\n",
    "            draw.text(pos, txt, fill=TEXT_COLOR)\n",
    "            \n",
    "        draw_text((10, LINE_HEIGHT), \"round %d, step %d\" % (self.nresets, self.nsteps))\n",
    "        draw_text((10, 2*LINE_HEIGHT), \"phi_k %.3f, phi %.3f, dphi %.3f, alpha %.3f (goal Â±%.3f)\" % (self.phi_k, self.phi, self.dphi, self.alpha, ALPHA_GOAL))\n",
    "        draw_text((10, 3*LINE_HEIGHT), \"reward %s\" % self.info['reward'])\n",
    "        draw_text((10, 4*LINE_HEIGHT), self.actions_log)\n",
    "            \n",
    "        dx = self.stick_len * np.cos(self.eye_phi)\n",
    "        dy = self.stick_len * np.sin(self.eye_phi)\n",
    "        draw_circle(self.base_x, self.base_y, CIRCLE_SIZE, BASE_CIRCLE_COLOR)\n",
    "        draw_line(self.base_x, self.base_y, self.base_x + dx, self.base_y + dy, STICK_COLOR, STICK_WIDTH)\n",
    "        draw_circle(self.eye_x, self.eye_y, CIRCLE_SIZE, EYE_CIRCLE_COLOR)\n",
    "        draw_circle(self.target_x, self.target_y, CIRCLE_SIZE, TARGET_CIRCLE_COLOR)\n",
    "               \n",
    "        return np.asarray(image)\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "appreciated-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eos = EyeOnStickEnv()\n",
    "#eos.reset()\n",
    "#eos.get_obs()\n",
    "#eos.step(1)\n",
    "#plt.imshow(eos.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-intranet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.common.cmd_util import make_vec_env\n",
    "from stable_baselines.common.vec_env import VecNormalize\n",
    "\n",
    "env = make_vec_env(lambda: EyeOnStickEnv(), n_envs=N_ENVS)\n",
    "env = VecNormalize(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from stable_baselines import ACKTR\n",
    "#policy=ACKTR\n",
    "from stable_baselines import PPO2\n",
    "policy = PPO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "if MODEL_FNAME is not None:\n",
    "    try:\n",
    "        model = PPO2.load(MODEL_FNAME)\n",
    "        logger.debug(\"model loaded from '%s'\" % (MODEL_FNAME))\n",
    "    except ValueError as ex:\n",
    "        logger.debug(\"could not load model from '%s', starting anew\" % (MODEL_FNAME))\n",
    "else:\n",
    "    logger.debug(\"model loading disabled, starting anew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model is None:\n",
    "    model = policy('MlpLnLstmPolicy', env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-berlin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-moscow",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:   \n",
    "    n_victories, n_losses = 0, 0\n",
    "    n_steps = np.zeros(N_ENVS)\n",
    "    \n",
    "    obs = env.reset()\n",
    "\n",
    "    while n_losses == 0:\n",
    "        display.clear_output(wait=True)\n",
    "        showarray(env.render(mode='rgb_array'))\n",
    "\n",
    "        actions, _ = model.predict(obs, deterministic=True)\n",
    "        obs, _, dones, _ = env.step(actions)\n",
    "        \n",
    "        for i, done in enumerate(dones):\n",
    "            if done:\n",
    "                logger.debug(\"[%2d] goal reached after %d steps (%d victories)\" % (i, n_steps[i], n_victories))\n",
    "                n_victories += 1\n",
    "                n_steps[i] = 0\n",
    "                n_steps_since_done = 0\n",
    "            if n_steps[i] > MAX_STEPS:\n",
    "                logger.debug(\"[%2d] goal not reached after %d steps\" % (i, n_steps[i]))\n",
    "                n_losses += 1\n",
    "                \n",
    "        n_steps += 1\n",
    "        \n",
    "    n_learn_epochs = 2000 * N_ENVS\n",
    "    logger.debug(\"%d victories, %d losses, back to school for %d epochs ...\" % (n_victories, n_losses, n_learn_epochs))\n",
    "    model.learn(n_learn_epochs)\n",
    "    if MODEL_FNAME is not None:\n",
    "        model.save(MODEL_FNAME)\n",
    "        logger.debug(\"learning completed, model saved in '%s'\" % (MODEL_FNAME))\n",
    "    else:\n",
    "        logger.debug(\"learning completed, model not saved\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-religion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
