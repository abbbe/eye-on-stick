{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython import display\n",
    "from lib.viz import showarray\n",
    "\n",
    "from stable_baselines import SAC\n",
    "from stable_baselines.common.vec_env import VecNormalize\n",
    "from stable_baselines.common.cmd_util import make_vec_env\n",
    "\n",
    "import os, time, json, io\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"sqlite:///mlruns/db.sqlite\"\n",
    "import mlflow\n",
    "mlflow_client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "from lib import eos\n",
    "\n",
    "#from lib.eos import EyeOnStickEnv\n",
    "#ENV = EyeOnStickEnv\n",
    "\n",
    "from lib.eos2d import EyeOnStickEnv2D\n",
    "ENV = EyeOnStickEnv2D\n",
    "\n",
    "from lib.run import run_env_nsteps\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-signal",
   "metadata": {},
   "outputs": [],
   "source": [
    "NJ = 3\n",
    "model_name, model_version = f\"eos.{NJ}J\", 287 # 213 # 38\n",
    "model, model_source = None, None\n",
    "\n",
    "params = {'GEAR_FUNC_NOISE': 0}\n",
    "\n",
    "lastrun_metrics = {}\n",
    "lastrun_trajs = None\n",
    "lastrun_gearfuncs = None\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4), dpi=224/4)\n",
    "colors=\"rgb\"\n",
    "\n",
    "while True:\n",
    "    if model_version is not None:\n",
    "        registered_model = mlflow_client.get_model_version(model_name, model_version)\n",
    "    else:\n",
    "        registered_model = mlflow_client.get_latest_versions(model_name, stages=[\"None\"])[0]\n",
    "        \n",
    "    #if model_source is None or model_source != registered_model.source:\n",
    "    model_source = registered_model.source\n",
    "    actual_model_version = registered_model.version\n",
    "    model = SAC.load(model_source)\n",
    "    \n",
    "    params_fname = f'{model_source}.json'\n",
    "    with open(params_fname, 'r') as fp:\n",
    "        loaded_params = json.load(fp)\n",
    "        \n",
    "    params = {**loaded_params, **params} # merge, overriding loaded params \n",
    "        \n",
    "    env = make_vec_env(lambda: ENV(NJ, params), n_envs=1)\n",
    "    model.set_env(env)\n",
    "    env.env_method('set_render_info', {'name': model_name, 'version': model_version, 'real_version': actual_model_version})\n",
    "\n",
    "    def get_metrics_dashboard(metrics):\n",
    "        dashboard_img = Image.new('RGB', (224, 224))\n",
    "        dashboard_draw = ImageDraw.Draw(dashboard_img)\n",
    "        \n",
    "        def draw_text(txt, vpos=0):\n",
    "            vpos += 1\n",
    "            dashboard_draw.text((10, 10*vpos), txt)\n",
    "            return vpos\n",
    "\n",
    "        # draw metrics\n",
    "        vpos = 0\n",
    "        for key, val in metrics.items():\n",
    "            vpos = draw_text(f'{key:15s} {val:+.4f}', vpos=vpos)\n",
    "        \n",
    "        return np.asarray(dashboard_img)\n",
    "    \n",
    "    def get_episode_dashboard1(gearfuncs, trajs):\n",
    "        if gearfuncs is None:\n",
    "            return np.zeros((224, 224, 3))\n",
    "\n",
    "        ax.cla()\n",
    "        ax.set_xlim([-eos.PHI_AMP, eos.PHI_AMP])\n",
    "        ax.set_ylim([-eos.PHI_AMP, eos.PHI_AMP])\n",
    "    \n",
    "        gfx = np.linspace(-eos.PHI_AMP, eos.PHI_AMP, 50)\n",
    "        for i, gf in enumerate(gearfuncs):\n",
    "            gfy = gf(gfx)\n",
    "            ax.scatter(gfx, gfy, 1, colors[i])\n",
    "\n",
    "        for i in range(trajs.shape[2]):\n",
    "            ax.scatter(trajs[:,0,i], trajs[:,1,i], 1, colors[i])\n",
    "        \n",
    "        io_buf = io.BytesIO()\n",
    "        fig.savefig(io_buf, format='raw')\n",
    "        io_buf.seek(0)\n",
    "        img_arr = np.reshape(np.frombuffer(io_buf.getvalue(), dtype=np.uint8),\n",
    "                             newshape=(int(fig.bbox.bounds[3]), int(fig.bbox.bounds[2]), -1))\n",
    "        io_buf.close()\n",
    "\n",
    "        return img_arr[:,:,[0,1,2]] # take only RGB from RGBA\n",
    "    \n",
    "    def get_episode_dashboard2(trajs):\n",
    "        if trajs is None:\n",
    "            return np.zeros((224, 224, 3))\n",
    "\n",
    "        ax.cla()\n",
    "        ax.autoscale(True)\n",
    "        for i in range(trajs.shape[2]):\n",
    "            ax.plot(range(trajs.shape[0]), trajs[:,0,i], colors[i])\n",
    "\n",
    "        io_buf = io.BytesIO()\n",
    "        fig.savefig(io_buf, format='raw')\n",
    "        io_buf.seek(0)\n",
    "        img_arr = np.reshape(np.frombuffer(io_buf.getvalue(), dtype=np.uint8),\n",
    "                             newshape=(int(fig.bbox.bounds[3]), int(fig.bbox.bounds[2]), -1))\n",
    "        io_buf.close()\n",
    "\n",
    "        return img_arr[:,:,[0,1,2]] # take only RGB from RGBA\n",
    "    \n",
    "    def get_episode_dashboard3(trajs):\n",
    "        if trajs is None:\n",
    "            return np.zeros((224, 224, 3))\n",
    "\n",
    "        ax.cla()\n",
    "        ax.autoscale(True)\n",
    "        for i in range(trajs.shape[2]):\n",
    "            ax.scatter(trajs[:,0,i], trajs[:,2,i], 1, colors[i]) # ... phi, dphi ...\n",
    "        ax.axhline(y=0.0, color='grey', linestyle='-')\n",
    "\n",
    "        io_buf = io.BytesIO()\n",
    "        fig.savefig(io_buf, format='raw')\n",
    "        io_buf.seek(0)\n",
    "        img_arr = np.reshape(np.frombuffer(io_buf.getvalue(), dtype=np.uint8),\n",
    "                             newshape=(int(fig.bbox.bounds[3]), int(fig.bbox.bounds[2]), -1))\n",
    "        io_buf.close()\n",
    "\n",
    "        return img_arr[:,:,[0,1,2]] # take only RGB from RGBA\n",
    "        \n",
    "#    def get_blank_dashboard():\n",
    "#        dashboard_img = Image.new('RGB', (224, 224))\n",
    "#        dashboard_draw = ImageDraw.Draw(dashboard_img)\n",
    "#        return np.asarray(dashboard_img)\n",
    "\n",
    "    def get_episode_dashboard(lastrun_gearfuncs, lastrun_trajs):\n",
    "        return np.hstack((\n",
    "            get_episode_dashboard1(lastrun_gearfuncs, lastrun_trajs),\n",
    "            get_episode_dashboard2(lastrun_trajs),\n",
    "            get_episode_dashboard3(lastrun_trajs)\n",
    "            #get_metrics_dashboard(lastrun_metrics)\n",
    "        ))\n",
    "                \n",
    "    # run the episode, collect images of rendered environment and trajectory data\n",
    "    # FIXME: era_env_render = np.zeros((params['MAX_NSTEPS'], eos.SCREEN_SIZE[0], eos.SCREEN_SIZE[1], 3))\n",
    "    lastrun_env_images = None\n",
    "    def displayfunc(img_array):\n",
    "        global lastrun_env_images\n",
    "        \n",
    "        img_array = np.hstack((img_array, env.envs[0].render_step_dashboard())) # FIXME\n",
    "        img_array = img_array[np.newaxis,...] # make it (1, SCREEN_SIZE-X, SCREEN_SIZE-y, 3)\n",
    "        if lastrun_env_images is None:\n",
    "            lastrun_env_images = img_array\n",
    "        else:\n",
    "            lastrun_env_images = np.vstack((lastrun_env_images, img_array))\n",
    "        # (?, SCREEN_SIZE-X, SCREEN_SIZE-y)\n",
    "\n",
    "    lastrun_trajs = None\n",
    "    def trajfunc(traj): # (3, NJ) where 3 corresponds to phi and _phi and dphi\n",
    "        global lastrun_trajs\n",
    "        traj = traj[np.newaxis,:,:] # make it (1, 2, NJ)\n",
    "        if lastrun_trajs is None:\n",
    "            lastrun_trajs = traj\n",
    "        else:\n",
    "            lastrun_trajs = np.vstack((lastrun_trajs, traj))\n",
    "        # (?, 2, NJ)\n",
    "\n",
    "    logger.debug(f\"run_env_nsteps: n_steps={params['MAX_NSTEPS']}\")\n",
    "    lastrun_metrics, data = run_env_nsteps(env, model, params['MAX_NSTEPS'], displayfunc=displayfunc, trajfunc=trajfunc)\n",
    "    lastrun_gearfuncs = list(env.envs[0].gearfuncs) # FIXME\n",
    "    \n",
    "    episode_dashboard_img_array = get_episode_dashboard(lastrun_gearfuncs, lastrun_trajs)\n",
    "    episode_dashboard_img_array = get_episode_dashboard(lastrun_gearfuncs, lastrun_trajs)\n",
    "        \n",
    "    for i in range(params['MAX_NSTEPS']):\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        #img_array = np.hstack(( # , episode_dashboard_img_array))\n",
    "        img_array = np.vstack((lastrun_env_images[i], episode_dashboard_img_array))\n",
    "        showarray(img_array)\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-contest",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
